{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-section",
   "metadata": {},
   "source": [
    "# Satellite Image Analysis - Unsupervised Classification Pipeline\n",
    "\n",
    "This notebook implements an unsupervised classification pipeline for satellite imagery using various feature extraction techniques and clustering algorithms.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. Load and preprocess satellite images\n",
    "2. Extract features (spectral, textural, edge, etc.)\n",
    "3. Apply dimensionality reduction (PCA)\n",
    "4. Perform clustering (K-means, MiniBatchKMeans)\n",
    "5. Visualize and analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1531cafe-b466-4b4c-959b-3c5d5c54a002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\dell\\Documents\\GitHub\\satellite-image-analysis\\notebooks\n",
      "Parent directory added to sys.path: C:\\Users\\dell\\Documents\\GitHub\\satellite-image-analysis\n",
      "sys.path: ['C:\\\\Users\\\\dell\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python311.zip', 'C:\\\\Users\\\\dell\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\DLLs', 'C:\\\\Users\\\\dell\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib', 'C:\\\\Users\\\\dell\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311', '', 'C:\\\\Users\\\\dell\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\dell\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\dell\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\dell\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\dell\\\\Documents\\\\GitHub\\\\satellite-image-analysis']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the parent directory (root of the project)\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Add to sys.path if not already present\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Verify\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Parent directory added to sys.path: {parent_dir}\")\n",
    "print(f\"sys.path: {sys.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "imports-section",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Import functions from utils module\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_tif_images, flatten_bands, scale_features\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Load images\u001b[39;00m\n\u001b[0;32m     23\u001b[0m images, paths \u001b[38;5;241m=\u001b[39m load_tif_images(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/dell/Documents/GitHub/satellite-image-analysis/data/sample\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils.preprocessing'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.filters import sobel, laplace, gaussian\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.exposure import rescale_intensity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import functions from utils module\n",
    "from utils.preprocessing import load_tif_images, flatten_bands, scale_features\n",
    "\n",
    "# Load images\n",
    "images, paths = load_tif_images(\"C:/Users/dell/Documents/GitHub/satellite-image-analysis/data/sample\")\n",
    "\n",
    "# Process each image\n",
    "for img in images:\n",
    "    flattened = flatten_bands(img)  # (H*W, C)\n",
    "    scaled = scale_features(flattened)  # Normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-section",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "First, we'll load the satellite images from the data directory and examine their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory path (adjust as needed for your environment)\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'data', 'sample'))\n",
    "print(f\"Loading images from: {data_dir}\")\n",
    "\n",
    "# Load raw images\n",
    "images, paths = load_tif_images(data_dir)\n",
    "print(f\"Loaded {len(images)} images.\")\n",
    "\n",
    "# Display information about the first image\n",
    "if len(images) > 0:\n",
    "    sample_image = images[0]\n",
    "    print(f\"\\nSample image shape: {sample_image.shape}\")\n",
    "    print(f\"Number of bands: {sample_image.shape[0]}\")\n",
    "    print(f\"Image dimensions (height × width): {sample_image.shape[1]} × {sample_image.shape[2]}\")\n",
    "    print(f\"Data type: {sample_image.dtype}\")\n",
    "    print(f\"Min value: {sample_image.min()}, Max value: {sample_image.max()}\")\n",
    "    \n",
    "    # Display the filename of the sample image\n",
    "    print(f\"Sample image filename: {os.path.basename(paths[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-section",
   "metadata": {},
   "source": [
    "## 2. Basic Image Visualization\n",
    "\n",
    "Let's visualize the sample image using different band combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-bands",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_rgb_composite(image, rgb_bands=[0, 1, 2], title=\"RGB Composite\", figsize=(10, 8)):\n",
    "    \"\"\"Display an RGB composite image using specified bands.\"\"\"\n",
    "    # Extract the specified bands and transpose to (height, width, channels) for plotting\n",
    "    rgb = np.dstack([image[band] for band in rgb_bands])\n",
    "    \n",
    "    # Normalize values to 0-1 range for display\n",
    "    rgb_norm = np.zeros_like(rgb, dtype=np.float32)\n",
    "    for i in range(3):\n",
    "        band_min, band_max = np.percentile(rgb[:,:,i], (2, 98))\n",
    "        rgb_norm[:,:,i] = np.clip((rgb[:,:,i] - band_min) / (band_max - band_min), 0, 1)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(rgb_norm)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display RGB composite (assuming bands are in order: R, G, B, NIR)\n",
    "if len(images) > 0:\n",
    "    # True color composite (RGB)\n",
    "    display_rgb_composite(images[0], rgb_bands=[0, 1, 2], title=\"True Color Composite (RGB)\")\n",
    "    \n",
    "    # False color composite (NIR, R, G)\n",
    "    display_rgb_composite(images[0], rgb_bands=[3, 0, 1], title=\"False Color Composite (NIR, R, G)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-extraction-section",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction\n",
    "\n",
    "We'll extract various features from the satellite images for clustering:\n",
    "1. Spectral bands (RGB, NIR)\n",
    "2. Spectral indices (NDVI, band ratios)\n",
    "3. Textural features (GLCM)\n",
    "4. Edge and shape features\n",
    "5. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectral-indices",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndvi(image):\n",
    "    \"\"\"Calculate Normalized Difference Vegetation Index (NDVI).\n",
    "    Assumes band order: R, G, B, NIR\"\"\"\n",
    "    # Extract red and near-infrared bands\n",
    "    red = image[0].astype(float)\n",
    "    nir = image[3].astype(float)\n",
    "    \n",
    "    # Calculate NDVI: (NIR - Red) / (NIR + Red)\n",
    "    # Add small epsilon to avoid division by zero\n",
    "    epsilon = 1e-10\n",
    "    ndvi = (nir - red) / (nir + red + epsilon)\n",
    "    \n",
    "    return ndvi\n",
    "\n",
    "def calculate_band_ratios(image):\n",
    "    \"\"\"Calculate various band ratios.\n",
    "    Assumes band order: R, G, B, NIR\"\"\"\n",
    "    # Extract bands\n",
    "    red = image[0].astype(float)\n",
    "    green = image[1].astype(float)\n",
    "    blue = image[2].astype(float)\n",
    "    nir = image[3].astype(float)\n",
    "    \n",
    "    # Add small epsilon to avoid division by zero\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    # Calculate ratios\n",
    "    red_green_ratio = red / (green + epsilon)\n",
    "    blue_green_ratio = blue / (green + epsilon)\n",
    "    nir_red_ratio = nir / (red + epsilon)\n",
    "    \n",
    "    return red_green_ratio, blue_green_ratio, nir_red_ratio\n",
    "\n",
    "# Calculate NDVI for the sample image\n",
    "if len(images) > 0:\n",
    "    ndvi = calculate_ndvi(images[0])\n",
    "    \n",
    "    # Visualize NDVI\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(ndvi, cmap='RdYlGn')\n",
    "    plt.colorbar(label='NDVI')\n",
    "    plt.title('Normalized Difference Vegetation Index (NDVI)')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate band ratios\n",
    "    red_green_ratio, blue_green_ratio, nir_red_ratio = calculate_band_ratios(images[0])\n",
    "    \n",
    "    # Visualize one of the band ratios\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(nir_red_ratio, cmap='viridis')\n",
    "    plt.colorbar(label='NIR/Red Ratio')\n",
    "    plt.title('NIR/Red Band Ratio')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textural-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(image, band_idx=0, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    \"\"\"Extract Gray-Level Co-occurrence Matrix (GLCM) textural features.\"\"\"\n",
    "    # Select a single band for GLCM calculation\n",
    "    band = image[band_idx]\n",
    "    \n",
    "    # Rescale to 0-255 and convert to uint8 for GLCM calculation\n",
    "    band_rescaled = rescale_intensity(band, out_range=(0, 255)).astype(np.uint8)\n",
    "    \n",
    "    # Calculate GLCM\n",
    "    glcm = greycomatrix(band_rescaled, distances=distances, angles=angles, \n",
    "                        levels=256, symmetric=True, normed=True)\n",
    "    \n",
    "    # Calculate GLCM properties\n",
    "    contrast = greycoprops(glcm, 'contrast')[0, 0]\n",
    "    dissimilarity = greycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "    homogeneity = greycoprops(glcm, 'homogeneity')[0, 0]\n",
    "    energy = greycoprops(glcm, 'energy')[0, 0]\n",
    "    correlation = greycoprops(glcm, 'correlation')[0, 0]\n",
    "    \n",
    "    return contrast, dissimilarity, homogeneity, energy, correlation\n",
    "\n",
    "def calculate_glcm_feature_maps(image, band_idx=0, window_size=15, step=15):\n",
    "    \"\"\"Calculate GLCM feature maps using a sliding window approach.\"\"\"\n",
    "    # Select a single band\n",
    "    band = image[band_idx]\n",
    "    height, width = band.shape\n",
    "    \n",
    "    # Initialize feature maps\n",
    "    contrast_map = np.zeros((height // step, width // step))\n",
    "    homogeneity_map = np.zeros_like(contrast_map)\n",
    "    energy_map = np.zeros_like(contrast_map)\n",
    "    \n",
    "    # Calculate GLCM features for each window\n",
    "    for i in range(0, height - window_size, step):\n",
    "        for j in range(0, width - window_size, step):\n",
    "            # Extract window\n",
    "            window = band[i:i+window_size, j:j+window_size]\n",
    "            \n",
    "            # Rescale to 0-255 and convert to uint8\n",
    "            window_rescaled = rescale_intensity(window, out_range=(0, 255)).astype(np.uint8)\n",
    "            \n",
    "            # Calculate GLCM\n",
    "            glcm = greycomatrix(window_rescaled, distances=[1], angles=[0], \n",
    "                                levels=256, symmetric=True, normed=True)\n",
    "            \n",
    "            # Calculate GLCM properties\n",
    "            contrast_map[i//step, j//step] = greycoprops(glcm, 'contrast')[0, 0]\n",
    "            homogeneity_map[i//step, j//step] = greycoprops(glcm, 'homogeneity')[0, 0]\n",
    "            energy_map[i//step, j//step] = greycoprops(glcm, 'energy')[0, 0]\n",
    "    \n",
    "    return contrast_map, homogeneity_map, energy_map\n",
    "\n",
    "# Calculate GLCM feature maps for the sample image\n",
    "if len(images) > 0:\n",
    "    # Use a smaller window size for demonstration\n",
    "    contrast_map, homogeneity_map, energy_map = calculate_glcm_feature_maps(images[0], band_idx=0, window_size=15, step=15)\n",
    "    \n",
    "    # Visualize GLCM feature maps\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    im0 = axes[0].imshow(contrast_map, cmap='hot')\n",
    "    axes[0].set_title('GLCM Contrast')\n",
    "    axes[0].axis('off')\n",
    "    plt.colorbar(im0, ax=axes[0])\n",
    "    \n",
    "    im1 = axes[1].imshow(homogeneity_map, cmap='viridis')\n",
    "    axes[1].set_title('GLCM Homogeneity')\n",
    "    axes[1].axis('off')\n",
    "    plt.colorbar(im1, ax=axes[1])\n",
    "    \n",
    "    im2 = axes[2].imshow(energy_map, cmap='plasma')\n",
    "    axes[2].set_title('GLCM Energy')\n",
    "    axes[2].axis('off')\n",
    "    plt.colorbar(im2, ax=axes[2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edge-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edge_features(image, band_idx=0):\n",
    "    \"\"\"Extract edge features using Sobel and Laplacian filters.\"\"\"\n",
    "    # Select a single band\n",
    "    band = image[band_idx]\n",
    "    \n",
    "    # Apply Sobel filter for edge detection\n",
    "    sobel_edges = sobel(band)\n",
    "    \n",
    "    # Apply Laplacian filter for edge detection\n",
    "    laplacian_edges = np.abs(laplace(band))\n",
    "    \n",
    "    return sobel_edges, laplacian_edges\n",
    "\n",
    "# Extract edge features for the sample image\n",
    "if len(images) > 0:\n",
    "    sobel_edges, laplacian_edges = extract_edge_features(images[0], band_idx=0)\n",
    "    \n",
    "    # Visualize edge features\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Original band\n",
    "    axes[0].imshow(images[0][0], cmap='gray')\n",
    "    axes[0].set_title('Original Band (Red)')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Sobel edges\n",
    "    axes[1].imshow(sobel_edges, cmap='magma')\n",
    "    axes[1].set_title('Sobel Edges')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Laplacian edges\n",
    "    axes[2].imshow(laplacian_edges, cmap='viridis')\n",
    "    axes[2].set_title('Laplacian Edges')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-combination-section",
   "metadata": {},
   "source": [
    "## 4. Feature Combination and Dimensionality Reduction\n",
    "\n",
    "Now we'll combine all the extracted features and apply PCA for dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(image):\n",
    "    \"\"\"Extract all features from an image and combine them.\"\"\"\n",
    "    # Get image dimensions\n",
    "    bands, height, width = image.shape\n",
    "    \n",
    "    # Initialize feature array\n",
    "    # Start with the original spectral bands\n",
    "    features = np.zeros((height * width, bands))\n",
    "    for b in range(bands):\n",
    "        features[:, b] = image[b].flatten()\n",
    "    \n",
    "    # Calculate NDVI\n",
    "    ndvi = calculate_ndvi(image)\n",
    "    features = np.column_stack((features, ndvi.flatten()))\n",
    "    \n",
    "    # Calculate band ratios\n",
    "    red_green_ratio, blue_green_ratio, nir_red_ratio = calculate_band_ratios(image)\n",
    "    features = np.column_stack((features, \n",
    "                               red_green_ratio.flatten(),\n",
    "                               blue_green_ratio.flatten(),\n",
    "                               nir_red_ratio.flatten()))\n",
    "    \n",
    "    # Extract edge features\n",
    "    sobel_edges, laplacian_edges = extract_edge_features(image, band_idx=0)\n",
    "    features = np.column_stack((features, \n",
    "                               sobel_edges.flatten(),\n",
    "                               laplacian_edges.flatten()))\n",
    "    \n",
    "    # Return the combined features\n",
    "    return features\n",
    "\n",
    "def apply_pca(features, n_components=3):\n",
    "    \"\"\"Apply PCA for dimensionality reduction.\"\"\"\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    features_pca = pca.fit_transform(features_scaled)\n",
    "    \n",
    "    # Print explained variance ratio\n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.4f}\")\n",
    "    \n",
    "    return features_pca, pca\n",
    "\n",
    "# Extract all features and apply PCA for the sample image\n",
    "if len(images) > 0:\n",
    "    # Extract features\n",
    "    all_features = extract_all_features(images[0])\n",
    "    print(f\"Combined feature shape: {all_features.shape}\")\n",
    "    \n",
    "    # Apply PCA\n",
    "    features_pca, pca_model = apply_pca(all_features, n_components=3)\n",
    "    print(f\"PCA feature shape: {features_pca.shape}\")\n",
    "    \n",
    "    # Visualize PCA components as an RGB image\n",
    "    height, width = images[0].shape[1], images[0].shape[2]\n",
    "    pca_rgb = features_pca.reshape(height, width, 3)\n",
    "    \n",
    "    # Normalize for visualization\n",
    "    pca_rgb_norm = np.zeros_like(pca_rgb)\n",
    "    for i in range(3):\n",
    "        pca_rgb_norm[:,:,i] = (pca_rgb[:,:,i] - pca_rgb[:,:,i].min()) / (pca_rgb[:,:,i].max() - pca_rgb[:,:,i].min())\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(pca_rgb_norm)\n",
    "    plt.title('PCA Components as RGB')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clustering-section",
   "metadata": {},
   "source": [
    "## 5. Clustering\n",
    "\n",
    "Now we'll apply K-means clustering to the extracted features and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kmeans-clustering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kmeans(features, n_clusters=5, random_state=42, use_minibatch=False, batch_size=1000):\n",
    "    \"\"\"Apply K-means clustering to the features.\"\"\"\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Apply K-means or MiniBatchKMeans\n",
    "    if use_minibatch:\n",
    "        kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=random_state, batch_size=batch_size)\n",
    "    else:\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n",
    "    \n",
    "    # Fit and predict\n",
    "    labels = kmeans.fit_predict(features_scaled)\n",
    "    \n",
    "    return labels, kmeans\n",
    "\n",
    "def visualize_clusters(image, labels, title=\"K-means Clustering\"):\n",
    "    \"\"\"Visualize clustering results.\"\"\"\n",
    "    # Reshape labels to image dimensions\n",
    "    height, width = image.shape[1], image.shape[2]\n",
    "    clustered_image = labels.reshape((height, width))\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(clustered_image, cmap='tab20')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show()\n",
    "    \n",
    "    return clustered_image\n",
    "\n",
    "# Apply K-means clustering to the PCA features\n",
    "if len(images) > 0 and 'features_pca' in locals():\n",
    "    # Try different numbers of clusters\n",
    "    for k in [3, 5, 7]:\n",
    "        # Apply K-means\n",
    "        labels, kmeans_model = apply_kmeans(features_pca, n_clusters=k)\n",
    "        \n",
    "        # Visualize clusters\n",
    "        clustered_image = visualize_clusters(images[0], labels, title=f\"K-means Clustering (k={k})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minibatch-section",
   "metadata": {},
   "source": [
    "### 5.1 MiniBatchKMeans for Large Datasets\n",
    "\n",
    "For larger datasets, we can use MiniBatchKMeans which is more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minibatch-kmeans",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MiniBatchKMeans to the original features (which might be larger)\n",
    "if len(images) > 0 and 'all_features' in locals():\n",
    "    # Apply MiniBatchKMeans\n",
    "    labels_mb, kmeans_mb_model = apply_kmeans(all_features, n_clusters=5, use_minibatch=True, batch_size=1000)\n",
    "    \n",
    "    # Visualize clusters\n",
    "    clustered_image_mb = visualize_clusters(images[0], labels_mb, title=\"MiniBatchKMeans Clustering (k=5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-section",
   "metadata": {},
   "source": [
    "## 6. Comparison of Different Clustering Results\n",
    "\n",
    "Let's compare the clustering results with different feature sets and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_feature_sets(image, k=5):\n",
    "    \"\"\"Compare clustering results with different feature sets.\"\"\"\n",
    "    # Get image dimensions\n",
    "    bands, height, width = image.shape\n",
    "    \n",
    "    # 1. Original spectral bands only\n",
    "    spectral_features = flatten_bands(image)\n",
    "    spectral_labels, _ = apply_kmeans(spectral_features, n_clusters=k)\n",
    "    \n",
    "    # 2. Spectral bands + NDVI\n",
    "    ndvi = calculate_ndvi(image)\n",
    "    spectral_ndvi_features = np.column_stack((spectral_features, ndvi.flatten()))\n",
    "    spectral_ndvi_labels, _ = apply_kmeans(spectral_ndvi_features, n_clusters=k)\n",
    "    \n",
    "    # 3. All features with PCA\n",
    "    all_features = extract_all_features(image)\n",
    "    features_pca, _ = apply_pca(all_features, n_components=10)\n",
    "    pca_labels, _ = apply_kmeans(features_pca, n_clusters=k)\n",
    "    \n",
    "    # Visualize comparison\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    # Original RGB image\n",
    "    rgb = np.dstack([image[0], image[1], image[2]])\n",
    "    rgb_norm = np.zeros_like(rgb, dtype=np.float32)\n",
    "    for i in range(3):\n",
    "        band_min, band_max = np.percentile(rgb[:,:,i], (2, 98))\n",
    "        rgb_norm[:,:,i] = np.clip((rgb[:,:,i] - band_min) / (band_max - band_min), 0, 1)\n",
    "    \n",
    "    axes[0].imshow(rgb_norm)\n",
    "    axes[0].set_title('Original RGB')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Spectral bands only\n",
    "    axes[1].imshow(spectral_labels.reshape((height, width)), cmap='tab20')\n",
    "    axes[1].set_title('Spectral Bands Only')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Spectral bands + NDVI\n",
    "    axes[2].imshow(spectral_ndvi_labels.reshape((height, width)), cmap='tab20')\n",
    "    axes[2].set_title('Spectral Bands + NDVI')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # All features with PCA\n",
    "    axes[3].imshow(pca_labels.reshape((height, width)), cmap='tab20')\n",
    "    axes[3].set_title('All Features with PCA')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Compare different feature sets\n",
    "if len(images) > 0:\n",
    "    compare_feature_sets(images[0], k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k-comparison-section",
   "metadata": {},
   "source": [
    "### 6.1 Comparison of Different K Values\n",
    "\n",
    "Let's compare the clustering results with different numbers of clusters (k values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-k-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_k_values(image, features, k_values=[3, 5, 7, 10]):\n",
    "    \"\"\"Compare clustering results with different k values.\"\"\"\n",
    "    # Get image dimensions\n",
    "    if len(image.shape) == 3:\n",
    "        bands, height, width = image.shape\n",
    "    else:\n",
    "        height, width = image.shape\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, len(k_values), figsize=(5*len(k_values), 5))\n",
    "    \n",
    "    # Apply K-means with different k values\n",
    "    for i, k in enumerate(k_values):\n",
    "        # Apply K-means\n",
    "        labels, _ = apply_kmeans(features, n_clusters=k)\n",
    "        \n",
    "        # Visualize clusters\n",
    "        axes[i].imshow(labels.reshape((height, width)), cmap='tab20')\n",
    "        axes[i].set_title(f'K = {k}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Compare different k values\n",
    "if len(images) > 0 and 'features_pca' in locals():\n",
    "    compare_k_values(images[0], features_pca, k_values=[3, 5, 7, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elbow-method-section",
   "metadata": {},
   "source": [
    "### 6.2 Elbow Method for Optimal K Selection\n",
    "\n",
    "We can use the Elbow Method to find the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elbow-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_method(features, k_range=range(2, 11)):\n",
    "    \"\"\"Apply the Elbow Method to find the optimal number of clusters.\"\"\"\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Calculate inertia for different k values\n",
    "    inertia = []\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(features_scaled)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "    \n",
    "    # Plot the Elbow curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_range, inertia, 'bo-')\n",
    "    plt.xlabel('Number of Clusters (k)')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.title('Elbow Method for Optimal k')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Apply the Elbow Method\n",
    "if len(images) > 0 and 'features_pca' in locals():\n",
    "    # Use a sample of features for efficiency\n",
    "    sample_size = min(10000, features_pca.shape[0])\n",
    "    sample_indices = np.random.choice(features_pca.shape[0], sample_size, replace=False)\n",
    "    features_sample = features_pca[sample_indices]\n",
    "    \n",
    "    elbow_method(features_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-processing-section",
   "metadata": {},
   "source": [
    "## 7. Batch Processing Multiple Images\n",
    "\n",
    "Now let's apply our pipeline to process multiple images in batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_batch(images, paths, n_clusters=5, max_images=3):\n",
    "    \"\"\"Process a batch of images using the unsupervised classification pipeline.\"\"\"\n",
    "    # Limit the number of images to process\n",
    "    n_images = min(len(images), max_images)\n",
    "    \n",
    "    # Process each image\n",
    "    for i in range(n_images):\n",
    "        print(f\"\\nProcessing image {i+1}/{n_images}: {os.path.basename(paths[i])}\")\n",
    "        \n",
    "        # Extract features\n",
    "        all_features = extract_all_features(images[i])\n",
    "        print(f\"  - Extracted {all_features.shape[1]} features\")\n",
    "        \n",
    "        # Apply PCA\n",
    "        features_pca, _ = apply_pca(all_features, n_components=10)\n",
    "        \n",
    "        # Apply K-means clustering\n",
    "        labels, _ = apply_kmeans(features_pca, n_clusters=n_clusters)\n",
    "        \n",
    "        # Visualize results\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Original RGB image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        rgb = np.dstack([images[i][0], images[i][1], images[i][2]])\n",
    "        rgb_norm = np.zeros_like(rgb, dtype=np.float32)\n",
    "        for j in range(3):\n",
    "            band_min, band_max = np.percentile(rgb[:,:,j], (2, 98))\n",
    "            rgb_norm[:,:,j] = np.clip((rgb[:,:,j] - band_min) / (band_max - band_min), 0, 1)\n",
    "        \n",
    "        plt.imshow(rgb_norm)\n",
    "        plt.title(f'Original RGB - {os.path.basename(paths[i])}')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Clustered image\n",
    "        plt.subplot(1, 2, 2)\n",
    "        height, width = images[i].shape[1], images[i].shape[2]\n",
    "        plt.imshow(labels.reshape((height, width)), cmap='tab20')\n",
    "        plt.title(f'K-means Clustering (k={n_clusters})')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Process a batch of images\n",
    "if len(images) > 1:\n",
    "    process_image_batch(images, paths, n_clusters=5, max_images=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-section",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we have implemented a complete unsupervised classification pipeline for satellite imagery. The pipeline includes:\n",
    "\n",
    "1. Loading and preprocessing satellite images\n",
    "2. Extracting various features:\n",
    "   - Spectral bands (RGB, NIR)\n",
    "   - Spectral indices (NDVI, band ratios)\n",
    "   - Textural features using GLCM (contrast, homogeneity, energy, etc.)\n",
    "   - Edge and shape features using Sobel and Laplacian filters\n",
    "3. Applying dimensionality reduction with PCA\n",
    "4. Performing clustering with K-means and MiniBatchKMeans\n",
    "5. Visualizing and comparing results with different feature sets and parameters\n",
    "\n",
    "This pipeline can be used for various applications such as land cover classification, change detection, and environmental monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-work-section",
   "metadata": {},
   "source": [
    "## 9. Future Work\n",
    "\n",
    "Potential improvements and extensions to this pipeline:\n",
    "\n",
    "1. Implement other clustering algorithms (DBSCAN, Hierarchical Clustering, etc.)\n",
    "2. Add more advanced feature extraction techniques (Gabor filters, wavelet transforms)\n",
    "3. Incorporate temporal information for time-series analysis\n",
    "4. Implement supervised classification methods for comparison\n",
    "5. Optimize the pipeline for large-scale processing\n",
    "6. Add quantitative evaluation metrics for clustering quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
